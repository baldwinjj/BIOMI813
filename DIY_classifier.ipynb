{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "from loadMNIST import LoadMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A DIY classifier\n",
    "In this notebook, we'll build a simple classifer to discriminate between 1's and 0's in the MNIST database.\n",
    "\n",
    "First, we'll construct a simple 2D feature space by projecting digit images onto hand-selected 0 and 1 templates. \n",
    "\n",
    "We'll then design a linear classifier by hand, just by looking at the distribution of MNIST images in our simple feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "We'll use the MNIST dataset for this exercise. First we'll load up the images and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load all MNIST images, then select out the 0 and 1 images\n",
    "\n",
    "mnist_trn_img = '/mnt/fast/MNIST/train-images-idx3-ubyte'\n",
    "mnist_trn_lab = '/mnt/fast/MNIST/train-labels-idx1-ubyte'\n",
    "mnist_val_img = '/mnt/fast/MNIST/t10k-images-idx3-ubyte'\n",
    "mnist_val_lab = '/mnt/fast/MNIST/t10k-labels-idx1-ubyte'\n",
    "\n",
    "mnist_trn_data = LoadMNIST(mnist_trn_img)\n",
    "mnist_val_data = LoadMNIST(mnist_val_img)\n",
    "mnist_trn_label = LoadMNIST(mnist_trn_lab)\n",
    "mnist_val_label = LoadMNIST(mnist_val_lab)\n",
    "\n",
    "target_one = 1\n",
    "target_zero = 0\n",
    "\n",
    "trn_ones = mnist_trn_data[mnist_trn_label==target_one].astype('float32')\n",
    "val_ones = mnist_val_data[mnist_val_label==target_one].astype('float32')\n",
    "\n",
    "trn_zeros = mnist_trn_data[mnist_trn_label==target_zero].astype('float32')\n",
    "val_zeros = mnist_val_data[mnist_val_label==target_zero].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##sanity check\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(trn_ones[0],cmap='gray')\n",
    "plt.title('one')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(trn_zeros[0],cmap='gray')\n",
    "plt.title('zero')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(val_ones[0],cmap='gray')\n",
    "plt.title('one')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(val_zeros[0],cmap='gray')\n",
    "plt.title('zero')\n",
    "\n",
    "pixel_res = trn_ones.shape[1]\n",
    "n_trn_ones = trn_ones.shape[0]\n",
    "n_val_ones = val_ones.shape[0]\n",
    "n_trn_zeros = trn_zeros.shape[0]\n",
    "n_val_zeros = val_zeros.shape[0]\n",
    "\n",
    "print 'there are %d ones and %d zeros in the training set' %(n_trn_ones,n_trn_zeros)\n",
    "print 'there are %d ones and %d zeros in the validation set' %(n_val_ones,n_val_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally a good idea to normalize the input data, so that feature space is not dominated by the \"brightness\" of images, but rather by their shape. To do this, we first subtract the mean from each image, then divide each image by it's magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##normalize images\n",
    "##note the use of np.newaxis to take advantage of broadcasting rules!\n",
    "for arr in [trn_ones, trn_zeros, val_ones, val_zeros]:\n",
    "    arr -= np.mean(arr,axis=(1,2))[:,np.newaxis,np.newaxis]  \n",
    "    arr /= np.sqrt(np.sum(arr**2,axis=(1,2)))[:,np.newaxis,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The feature space\n",
    "We'll construct a simple linear transform that maps each MNIST image into a point in a 2D feature space.\n",
    "\n",
    "The axes of this feature space will correspond to a 0-template and a 1-template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select two images from the training data to be \"templates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_temp_idx = np.random.randint(0,high=n_trn_ones)    ##random template selection\n",
    "zero_temp_idx = np.random.randint(0,high=n_trn_zeros)\n",
    "one_temp = trn_ones[one_temp_idx]\n",
    "zero_temp = trn_zeros[zero_temp_idx]\n",
    "\n",
    "##view your templates\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(one_temp,cmap='gray')\n",
    "plt.title('template for one')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zero_temp,cmap='gray')\n",
    "plt.title('template for zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{t_0}$ be the zero template, and $\\mathbf{t_1}$ be the one template. Let $\\mathbf{s}$ be an image in the training set. Map all training data images (both zeros and ones) into the 2D feature space defined\n",
    "\n",
    "$\\phi(\\mathbf{s}) = (\\mathbf{s} \\cdot \\mathbf{t_0}, \\mathbf{s} \\cdot \\mathbf{t_1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##first, we reshape the templates and stack them into a matrix\n",
    "temps = np.array([zero_temp.ravel() , one_temp.ravel()]).T\n",
    "print temps.shape\n",
    "\n",
    "##next we project each of the images onto the templates\n",
    "phi_s_ones = trn_ones.reshape((n_trn_ones,pixel_res**2)).dot(temps)\n",
    "print phi_s_ones.shape\n",
    "\n",
    "phi_s_zeros = trn_zeros.reshape((n_trn_zeros,pixel_res**2)).dot(temps)\n",
    "print phi_s_zeros.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##view the projections, assigning different colors to each class\n",
    "one_color = np.array([.8,.3,.6])  ##pink vector\n",
    "zero_color = np.array([.2,.6,.8])  ##blue vector\n",
    "\n",
    "plt.scatter(phi_s_ones[:,0], phi_s_ones[:,1],c=one_color,label='ones', alpha = 1)\n",
    "plt.scatter(phi_s_zeros[:,0], phi_s_zeros[:,1],c=zero_color,label='zeros', alpha = 0.25)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('projection onto zero template')\n",
    "plt.ylabel('projection onto one template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, images of ones hug the \"ones\" axis, and images of zeros hug the \"zeros\" axis. Now let's try to hand-code a discriminant surface into this feature space that separates out the two classes of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-coding a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we learned that linear discriminant functions:\n",
    "\n",
    "$y(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b$\n",
    "\n",
    "implicitly define a discriminant surface as all point $\\left \\{ \\mathbf{x}: y(\\mathbf{x})=0 \\right \\}$, that is, all points where the discriminant function is zero.\n",
    "\n",
    "For convenience, let's write a simple function called \"view_classes\" that takes a weight vector (1,2) and a bias (scalar) and colors the 2D plain according to class asignment. We also write a simple discriminant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##a discriminant function\n",
    "def discriminant_function(data,weight_vector,bias):\n",
    "    '''\n",
    "    discriminant_function(data,weight_vector,bias)\n",
    "    data = N x 2\n",
    "    weight_vector = N x 1 array\n",
    "    bias = scalar\n",
    "    returns y(x) = (w.dot(x)+b) > 0\n",
    "    '''\n",
    "    return (weight_vector.dot(data)+bias) >= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view_class(weight_vector, bias, view_bounds=(-.5,1.5), view_res=100):\n",
    "    '''\n",
    "    view_class(weight_vector, bias, view_bounds=(-.5,1.5), view_res=100)\n",
    "    weight_vector = 2 x 1 array\n",
    "    bias = scalar\n",
    "    view_bounds ~ tuple of min,max bounds on the data.\n",
    "    view_res ~ integer: number of points along x and y axis for viewing discriminant results\n",
    "    '''\n",
    "    ##construct a viewing plane\n",
    "    X,Y = np.meshgrid(np.linspace(view_bounds[0],view_bounds[1],num=view_res),\n",
    "                      np.linspace(view_bounds[0],view_bounds[1],num=view_res))\n",
    "    \n",
    "    points = np.array([X.ravel(),Y.ravel()]) ##2 x view_res**2\n",
    "    \n",
    "    ##evaluate discriminate function\n",
    "    disc = discriminant_function(points,weight_vector,bias)\n",
    "    \n",
    "    \n",
    "    ##reshape disc. function values into a matrix and view\n",
    "    plt.pcolor(X,Y,disc.reshape((view_res,view_res)),cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    return disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out a few values of w and b to see if they'll give us decent classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##test with\n",
    "w = np.array([-1.5,1])\n",
    "b = .01\n",
    "_ = view_class(w, b)\n",
    "\n",
    "\n",
    "plt.scatter(phi_s_ones[:,0], phi_s_ones[:,1],c=one_color,label='ones', alpha = 1)\n",
    "plt.scatter(phi_s_zeros[:,0], phi_s_zeros[:,1],c=zero_color,label='zeros', alpha = 0.25)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('projection onto zero template')\n",
    "plt.ylabel('projection onto one template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can learn a lot about the quality of our hand-coded solution simply by inspecting the plot above. But we also need to quantify performance of the classifier. We'll use \"percent correct\" as our metric. For each point in our training set, we'll evaluate whether it is classified as a \"0\" ($y(\\mathbf{x}) <0$) or a \"1\" ($y(\\mathbf{x}) \\geq 0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_preds = discriminant_function(phi_s_ones.T, w,b)  ##true == correct\n",
    "zero_preds = discriminant_function(phi_s_zeros.T, w,b)  ##false == correct\n",
    "\n",
    "trn_one_correct = np.sum(one_preds==True)/float(len(one_preds))\n",
    "trn_zero_correct = np.sum(zero_preds==False)/float(len(one_preds))\n",
    "\n",
    "print 'percentage of correct ones, training set:  %0.2f' %(trn_one_correct)\n",
    "print 'percentage of correct zeros: training_set: %0.2f' %(trn_zero_correct)\n",
    "print 'total percent correct: %0.2f' %((trn_one_correct+trn_zero_correct)/2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well are we doing? Tweak \"weight_vector\" and \"bias\" to see if we can get something better...\n",
    "Then, repeat the above calculations for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brute force optimization\n",
    "Since our parameter space is pretty small, we can try to optimize our model by simply iterating over some range of reasonable model parameter values, and then just picking the one with the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "w_1_range = np.linspace(-1,1,num=num_steps)\n",
    "w_2_range = np.linspace(-1,1,num=num_steps)\n",
    "bias_range = np.linspace(-1,1,num=num_steps)\n",
    "b = 0.0\n",
    "trn_performance = np.zeros([num_steps]*2)\n",
    "for ii,w1 in enumerate(w_1_range):\n",
    "    for jj,w2 in enumerate(w_2_range):\n",
    "        w = np.array([w1,w2])\n",
    "        one_preds = discriminant_function(phi_s_ones.T, w,b)  ##true == correct\n",
    "        zero_preds = discriminant_function(phi_s_zeros.T, w,b)  ##false == correct\n",
    "        trn_one_correct = np.sum(one_preds==True)/float(len(one_preds))\n",
    "        trn_zero_correct = np.sum(zero_preds==False)/float(len(one_preds))\n",
    "        trn_performance[ii,jj] = (trn_one_correct+trn_zero_correct)/2.\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolor(w_1_range,w_2_range,trn_performance)\n",
    "plt.title('performance surface')\n",
    "plt.colorbar()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('w1')\n",
    "plt.ylabel('w2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution with the best training peformance is probably the one you came up with via hand-coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_idx = np.unravel_index(trn_performance.argmax(), trn_performance.shape)\n",
    "best_solution = np.array((w_1_range[best_idx[0]],w_2_range[best_idx[1]]))\n",
    "print 'best training performance: %0.2f' %(trn_performance[best_idx[0],best_idx[1]])\n",
    "print 'corresponding solution: w = (%0.2f, %0.2f)' %(w_1_range[best_idx[0]],w_2_range[best_idx[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation performance\n",
    "So far, we've tested the performance on the training set. But to really know how our model is doing, we need to test it on a novel data set that the model was optimized on. This is known as the \"validation\" data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##project validation images onto templates to get feature space data\n",
    "val_phi_s_ones = val_ones.reshape((n_val_ones,pixel_res**2)).dot(temps)\n",
    "val_phi_s_zeros = val_zeros.reshape((n_val_zeros,pixel_res**2)).dot(temps)\n",
    "\n",
    "one_preds = discriminant_function(val_phi_s_ones.T, best_solution,b)  ##true == correct\n",
    "zero_preds = discriminant_function(val_phi_s_zeros.T, best_solution,b)  ##false == correct\n",
    "val_one_correct = np.sum(one_preds==True)/float(len(one_preds))\n",
    "val_zero_correct = np.sum(zero_preds==False)/float(len(one_preds))\n",
    "validation_performance = (val_one_correct+val_zero_correct)/2.\n",
    "print 'validation performance: %0.2f' %(validation_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_ = view_class(best_solution, b)\n",
    "plt.scatter(val_phi_s_ones[:,0], val_phi_s_ones[:,1],c=one_color,label='ones', alpha = 1)\n",
    "plt.scatter(val_phi_s_zeros[:,0], val_phi_s_zeros[:,1],c=zero_color,label='zeros', alpha = 0.25)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('projection onto zero template')\n",
    "plt.ylabel('projection onto one template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the model's performance on the validation is only slightly worse than the performance on the training data. That's only because this is a really easy toy problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Zeros and ones are pretty easy to distinguish because they have very different shapes. Build a hand-coded classifier for ones and sevens, or threes and eights. How much worse is the performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "We constructed a feature space by using a randomly selected image of \"1\" and \"0\" as templates. \n",
    "\n",
    "Try to improve the performance of your DIY classifier via a more principled selection of templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization to multiple classes\n",
    "When there are more than two classes to discriminate, we build a model with multiple discriminant functions.\n",
    "Suppose we have $K$ classes and some $D$-dimensional data points. Then we define $K$ discriminant functions $y_1(\\mathbf{x}), \\ldots , y_1(\\mathbf{x})$, each of which has its own weight vector and bias:\n",
    "\n",
    "$y_k(\\mathbf{x}) = \\mathbf{w}_k \\cdot \\mathbf{x} + b_k$\n",
    "\n",
    "We will then say that a data point $\\mathbf{x}$ belongs to class $k$ as whenever $y_k(\\mathbf{x}) > y_j(\\mathbf{x})$ for any $j \\neq k$.\n",
    "\n",
    "We can formalize this model by stacking all of the weight vectors $\\mathbf{w}_k$ together as the rows of a single matrix $W$, reserving the first column for the bias terms $b_k$:\n",
    "\n",
    "$W = \\begin{bmatrix} -&\\mathbf{w}^T_1&-\\\\ \\quad&\\ldots&\\quad \\\\ -&\\mathbf{w}^T_K&- \\end{bmatrix}$\n",
    "\n",
    "where $\\mathbf{w}^T_k = \\left (b_k, w_{k1}, \\ldots, w_{kD} \\right ) $\n",
    "\n",
    "This will give us a vector-valued linear discriminant:\n",
    "\n",
    "$\\mathbf{y}(\\mathbf{x}) = W\\mathbf{x}$,\n",
    "\n",
    "where by convention we append a $1$ to each data point to account for the bias term:\n",
    "\n",
    "$\\mathbf{x} = \\begin{bmatrix} 1\\\\x_1\\\\ \\vdots\\\\ x_D \\end{bmatrix}$\n",
    "\n",
    "Then the class label $C_i$ for a single data point $\\mathbf{x}_i$ is just:\n",
    "\n",
    "$C_i = \\underset{k}{\\operatorname{argmax}} \\mathbf{y}(\\mathbf{x}_i)$\n",
    "\n",
    "Note that $\\mathbf{y}(\\mathbf{x})$ is $K x 1$ vector, as it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Generalize the functions \"discriminant_function\" and \"view_class\" to the multi-class setting. Use these functions to hand code a $K=3$ classifer (e.g., 1's, 0's, and 2's). In order to make visualization possible, use only two template images (of your chosing) to define the feature space (i.e., $D=2$).\n",
    "\n",
    "*Note*: Chances are you won't get very good performance in this $K > D$ setting. We might expect better performance when $K \\geq D$, but that will require new methods, which we'll cover next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
