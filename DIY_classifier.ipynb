{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from loadMNIST import LoadMNIST\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A DIY classifier\n",
    "In this notebook, we'll build a simple classifer to discriminate between 1's and 0's in the MNIST database.\n",
    "\n",
    "First, we'll construct a simple 2D feature space by projecting digit images onto hand-selected 0 and 1 templates. \n",
    "\n",
    "We'll then design a linear classifier by hand, just by looking at the distribution of MNIST images in our simple feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "We'll use the MNIST dataset for this exercise. First we'll load up the images and normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##load all MNIST images, then select out the 0 and 1 images\n",
    "\n",
    "mnist_trn_img = '/mnt/fast/MNIST/train-images-idx3-ubyte'\n",
    "mnist_trn_lab = '/mnt/fast/MNIST/train-labels-idx1-ubyte'\n",
    "mnist_val_img = '/mnt/fast/MNIST/t10k-images-idx3-ubyte'\n",
    "mnist_val_lab = '/mnt/fast/MNIST/t10k-labels-idx1-ubyte'\n",
    "\n",
    "mnist_trn_data = LoadMNIST(mnist_trn_img)\n",
    "mnist_val_data = LoadMNIST(mnist_val_img)\n",
    "mnist_trn_label = LoadMNIST(mnist_trn_lab)\n",
    "mnist_val_label = LoadMNIST(mnist_val_lab)\n",
    "\n",
    "trn_ones = mnist_trn_data[mnist_trn_label==1].astype('float32')\n",
    "val_ones = mnist_val_data[mnist_val_label==1].astype('float32')\n",
    "\n",
    "trn_zeros = mnist_trn_data[mnist_trn_label==0].astype('float32')\n",
    "val_zeros = mnist_val_data[mnist_val_label==0].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##sanity check\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(trn_ones[0],cmap='gray')\n",
    "plt.title('one')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(trn_zeros[0],cmap='gray')\n",
    "plt.title('zero')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(val_ones[0],cmap='gray')\n",
    "plt.title('one')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(val_zeros[0],cmap='gray')\n",
    "plt.title('zero')\n",
    "\n",
    "pixel_res = trn_ones.shape[1]\n",
    "n_trn_ones = trn_ones.shape[0]\n",
    "n_val_ones = val_ones.shape[0]\n",
    "n_trn_zeros = trn_zeros.shape[0]\n",
    "n_val_zeros = val_zeros.shape[0]\n",
    "\n",
    "print 'there are %d ones and %d zeros in the training set' %(n_trn_ones,n_trn_zeros)\n",
    "print 'there are %d ones and %d zeros in the validation set' %(n_val_ones,n_val_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is generally a good idea to normalize the input data, so that feature space is not dominated by the \"brightness\" of images, but rather by their shape. To do this, we first subtract the mean from each image, then divide each image by it's magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##normalize images\n",
    "##note the use of np.newaxis to take advantage of broadcasting rules!\n",
    "for arr in [trn_ones, trn_zeros, val_ones, val_zeros]:\n",
    "    arr -= np.mean(arr,axis=(1,2))[:,np.newaxis,np.newaxis]  \n",
    "    arr /= np.sqrt(np.sum(arr**2,axis=(1,2)))[:,np.newaxis,np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The feature space\n",
    "We'll construct a simple linear transform that maps each MNIST image into a point in a 2D feature space.\n",
    "\n",
    "The axes of this feature space will correspond to a 0-template and a 1-template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select two images from the training data to be \"templates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_temp_idx = np.random.randint(0,high=n_trn_ones)    ##random template selection\n",
    "zero_temp_idx = np.random.randint(0,high=n_trn_zeros)\n",
    "one_temp = trn_ones[one_temp_idx]\n",
    "zero_temp = trn_zeros[zero_temp_idx]\n",
    "\n",
    "##view your templates\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(one_temp,cmap='gray')\n",
    "plt.title('template for one')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(zero_temp,cmap='gray')\n",
    "plt.title('template for zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{t_0}$ be the zero template, and $\\mathbf{t_1}$ be the one template. Let $\\mathbf{s}$ be an image in the training set. Map all training data images (both zeros and ones) into the 2D feature space defined\n",
    "\n",
    "$\\phi(\\mathbf{s}) = (\\mathbf{s} \\cdot \\mathbf{t_0}, \\mathbf{s} \\cdot \\mathbf{t_1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##first, we reshape the templates and stack them into a matrix\n",
    "temps = np.array([zero_temp.ravel() , one_temp.ravel()]).T\n",
    "print temps.shape\n",
    "\n",
    "##next we project each of the temp\n",
    "phi_s_ones = trn_ones.reshape((n_trn_ones,pixel_res**2)).dot(temps)\n",
    "print phi_s_ones.shape\n",
    "\n",
    "phi_s_zeros = trn_zeros.reshape((n_trn_zeros,pixel_res**2)).dot(temps)\n",
    "print phi_s_zeros.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##view the projections, assigning different colors to each class\n",
    "plt.scatter(phi_s_ones[:,0], phi_s_ones[:,1],c=[1,0,0],label='ones', alpha = 1)\n",
    "plt.scatter(phi_s_zeros[:,0], phi_s_zeros[:,1],c=[0,0,1],label='zeros', alpha = 0.5)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('projection onto zero template')\n",
    "plt.ylabel('projection onto one template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, images of ones hug the \"ones\" axis, and images of zeros hug the \"zeros\" axis. Now let's try to hand-code a discriminant surface into this feature space that separates out the two classes of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-coding a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we learned that linear discriminant functions:\n",
    "\n",
    "$y(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b$\n",
    "\n",
    "implicitly define a discriminant surface as all point $\\left \\{ \\mathbf{x}: y(\\mathbf{x})=0 \\right \\}$, that is, all points where the discriminant function is zero.\n",
    "\n",
    "For convenience, let's write a simple function called \"view_classes\" that takes a weight vector (1,2) and a bias (scalar) and colors the 2D plain according to class asignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    X,Y = np.meshgrid(np.linspace(0,1,num=10),\n",
    "                      np.linspace(0,1,num=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array([X.ravel(),Y.ravel()]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def view_class(weight_vector, bias, view_bounds=(-.5,1.5), view_res=100):\n",
    "    ##construct a viewing plane\n",
    "    X,Y = np.meshgrid(np.linspace(view_bounds[0],view_bounds[1],num=view_res),\n",
    "                      np.linspace(view_bounds[0],view_bounds[1],num=view_res))\n",
    "    \n",
    "    points = np.array([X.ravel(),Y.ravel()]) ##2 x view_res**2\n",
    "    \n",
    "    ##evaluate discriminate function\n",
    "    disc = weight_vector.dot(points)+bias\n",
    "    \n",
    "    ##threshold\n",
    "    disc = (disc >= 0)\n",
    "    \n",
    "    ##reshape disc. function values into a matrix and view\n",
    "    plt.pcolor(X,Y,disc.reshape((view_res,view_res)),cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    \n",
    "    return disc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try out a few values of w and b to see if they'll give us decent classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##test with w = (-1,1), b = 1\n",
    "_ = view_class(np.array([-1,.5]), -.28)\n",
    "\n",
    "x_color = np.array([.8,.3,.6])  ##pink vector\n",
    "y_color = np.array([.2,.6,.8])  ##blue vector\n",
    "\n",
    "plt.scatter(phi_s_ones[:,0], phi_s_ones[:,1],c=x_color,label='ones', alpha = 1)\n",
    "plt.scatter(phi_s_zeros[:,0], phi_s_zeros[:,1],c=y_color,label='zeros', alpha = 0.5)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.xlabel('projection onto zero template')\n",
    "plt.ylabel('projection onto one template')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
