{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1: Linearity and depth\n",
    "Show that a network composed of two linear fully connected layers (i.e. layer that perform the affine transformation $x_{i+1} = W_ix_i+b_i$) is equivalent to a single linear fully connected layer. Note that, by using recursivity, one could show that this property holds for network of any depth if they are solely composed of such layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: Accuracies\n",
    "Explain in your own words what the training and validation accuracy are. Give and interpret one situation in which the validation accuracy may be greater than the training accuracy. Give and interpret one situation where the validation accuracy may be less than the training accuracy. What does it tell us about our model? What does it tell us about our dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3: Multilayer perceptron\n",
    "\"model_2\" in lasagne_MLP_classifier_example.ipynb is composed of a single layer with N nodes with a nonlinearity followed by a linear classifier. Define a similar \"model_3\" multi-layer perceptron networks with 2 consecutive layers of N/2 output nodes each applying a rectifier nonlinearities (and again with a final linear classifier on top), train it, and record your observations (final training and validation accuracy, number of iteration you trained it, etc.). How do the \"model_2\" and \"model_3\" networks compare? How many parameters do each of these networks contain? Briefly explain your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4: Convolutional network\n",
    "One type of transformation that has gained prominence in neural network architecture is the convolutional layer. The reason for this is that the convolution operation possesses a property called \"equivariance\", which is closely related to spatial invariance. Equivariance means \"vary in the same way as\". Coupled with max-pooling, which means taking the maximum activation value in a certain spatial region, the resulting activation often shows spatial invariance over small position changes in an image.\n",
    "\n",
    "A convolutional layer consists of a small \"local\" dense network (the parameter kernel) which is, in effect, repeated over different spatial locations. The kernel, which consists of all the learnable parameters, is the same regardless of the position at which it is applied. In lasagne, the convolutional layer is defined as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne.layers as L\n",
    "L.Conv2DLayer(incoming, num_filters, filter_size, stride, pad, W, b, nonlinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where \"incoming\" is the layer below, \"num_filters\" is the output dimension of the convolutional kernel (the total number of spatial convolution performed is the feature dimension of the input times this number (of features) of the output), \"filter_size\" is the size of the kernel window, \"stride\" is the step size used when sliding this kernel window across the input, \"pad\" is some extra dimension applied to the input, \"W\" and \"b\" are the kernel parameters to be initialized and \"nonlinearity\" is an optional nonlinearity applied after the convolution operation.\n",
    "\n",
    "A pooling layer specify a set of regions whose positions and sizes in a certain feature map are defined by \"pool_size\" and \"stride\", into each of which the maximum value is calculated. In lasagne, max pooling is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L.MaxPool2DLayer(incoming, pool_size, stride) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let \"XcYsZ\" indicate a (c)onvolutional layer for \"X\" output features with kernel size \"Y\" and (s)tride \"Z\", and let \"Xf\" indicate a fully connected layer with \"X\" output features. Note that we don't need to specify the input feature size because it is directly calculable in terms of all preceding layers and the network input. Furthermore, let's use a rectifier nonlinearity everywhere except the last layer where we will use no nonlinearity. Finally, in the shorthand notation, a pooling layer is indicated as \"pXsY\" for a (p)ooling size \"X\" and stride \"Y\".\n",
    "\n",
    "With this in mind, construct the following network: \"input\" -> 64c7s3 -> 128c3s1 -> p2s1 -> 512f -> 10f, where the output of the last layer \"10f\" is an embedding of the digit label prediction.\n",
    "\n",
    "a) How many parameters are contained in this network? Briefly explain your reasoning.\n",
    "\n",
    "b) Use the framework we have developped (or any other framework in which you feel more confortable, as long as it is at least equality expressive) to train this network on the MNIST dataset and record your results. How do they compare with the MLP networks of Exercise 3?\n",
    "\n",
    "Note: The weight initialization matters. Try using random normal noise with low variance like \"I.Normal(0.02)\" or start from homogeneous zero values with \"I.Constant(0.)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
